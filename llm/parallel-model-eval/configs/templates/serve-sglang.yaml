# Configuration for serving models with SGLang
# SGLang is a fast serving framework with advanced batching and optimization

envs:
  MODEL_PATH: meta-llama/Llama-2-7b-hf  # Default model path
  API_TOKEN: default-token

resources:
  accelerators: L4:1
  ports: 8000

setup: |
  # Create virtual environment
  uv venv --seed --python=3.10
  source .venv/bin/activate
  
  # Install SGLang
  uv pip install "sglang[all]"
  
  # Install flashinfer for optimized attention
  uv pip install flashinfer-python

run: |
  source .venv/bin/activate
  echo "Starting SGLang server for model: $MODEL_PATH"
  
  # Start SGLang server with OpenAI-compatible API
  python -m sglang.launch_server \
    --model-path $MODEL_PATH \
    --host 0.0.0.0 \
    --port 8000 \
    --api-key "$API_TOKEN" \
    --tp-size $SKYPILOT_NUM_GPUS_PER_NODE \
    --context-length 2048 \
    --mem-fraction-static 0.85