# This example is used to test the NCCL performance with
# InfiniBand on managed Nebius Kubernetes cluster without SkyPilot's network_tier.
#
# Usage:
#   sky launch -c nccl nebius_raw_nccl_test.yaml
#
# Tested on H200:8 on Nebius:
# (head, rank=0, pid=3405) [1,0]<stdout>:#                                                              out-of-place                       in-place          
# (head, rank=0, pid=3405) [1,0]<stdout>:#       size         count      type   redop    root     time   algbw   busbw #wrong     time   algbw   busbw #wrong
# (head, rank=0, pid=3405) [1,0]<stdout>:#        (B)    (elements)                               (us)  (GB/s)  (GB/s)            (us)  (GB/s)  (GB/s)       
# (head, rank=0, pid=3405) [1,0]<stdout>:   536870912     134217728     float     sum      -1   2396.4  224.04  420.07      0   2369.4  226.58  424.84      0
# (head, rank=0, pid=3405) [1,0]<stdout>:  1073741824     268435456     float     sum      -1   4450.9  241.24  452.32      0   4459.5  240.77  451.45      0
# (head, rank=0, pid=3405) [1,0]<stdout>:  2147483648     536870912     float     sum      -1   8672.9  247.61  464.27      0   8664.8  247.84  464.70      0
# (head, rank=0, pid=3405) [1,0]<stdout>:  4294967296    1073741824     float     sum      -1    17032  252.17  472.82      0    17048  251.94  472.39      0
# (head, rank=0, pid=3405) [1,0]<stdout>:  8589934592    2147483648     float     sum      -1    33763  254.42  477.03      0    33678  255.06  478.24      0
# (head, rank=0, pid=3405) [1,0]<stdout>:# Avg bus bandwidth    : 457.81

name: nccl-test

envs:
  NCCL_IB_HCA: mlx5
  UCX_NET_DEVICES: mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_3:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1

resources:
  cpus: 100+
  memory: 1000+
  infra: k8s
  accelerators: H200:8
  image_id: docker:cr.eu-north1.nebius.cloud/nebius-benchmarks/nccl-tests:2.23.4-ubu22.04-cu12.4

num_nodes: 2

run: |  
  if [ "${SKYPILOT_NODE_RANK}" == "0" ]; then
    echo "Head node"

    # Total number of processes, NP should be the total number of GPUs in the cluster
    NP=$(($SKYPILOT_NUM_GPUS_PER_NODE * $SKYPILOT_NUM_NODES))

    # Append :${SKYPILOT_NUM_GPUS_PER_NODE} to each IP as slots
    nodes=""
    for ip in $SKYPILOT_NODE_IPS; do
      nodes="${nodes}${ip}:${SKYPILOT_NUM_GPUS_PER_NODE},"
    done
    nodes=${nodes::-1}
    echo "All nodes: ${nodes}"

    mpirun \
      --allow-run-as-root \
      --tag-output \
      -H $nodes \
      -np $NP \
      -N $SKYPILOT_NUM_GPUS_PER_NODE \
      --bind-to none \
      -x PATH \
      -x LD_LIBRARY_PATH \
      -x NCCL_DEBUG=INFO \
      -x NCCL_SOCKET_IFNAME=eth0 \
      -x NCCL_IB_HCA \
      -x UCX_NET_DEVICES \
      -x SHARP_COLL_ENABLE_PCI_RELAXED_ORDERING=1 \
      -x NCCL_COLLNET_ENABLE=0 \
      /opt/nccl-tests/build/all_reduce_perf \
      -b 512M \
      -e 8G \
      -f 2 \
      -g 1 \
      -c 1 \
      -w 5 \
      -n 10
  else
    echo "Worker nodes"
  fi

config:
  kubernetes:
    pod_config:
      spec:
        containers:
        - securityContext:
            capabilities:
              add:
              - IPC_LOCK
